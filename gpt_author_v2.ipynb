{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soulve/Hue-Browser-Controller/blob/deploy/gpt_author_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih8GSkb28daX"
      },
      "source": [
        "# gpt-author v2\n",
        "By Matt Shumer (https://twitter.com/mattshumer_)\n",
        "\n",
        "Github repo: https://github.com/mshumer/gpt-author\n",
        "\n",
        "Generate an entire novel in minutes, and automatically package it as an e-book.\n",
        "\n",
        "To generate a book:\n",
        "1.  In the first cell, add in your OpenAI, Stability, and (optionally, Anthropic) keys (see the first cell for instructions to get them).\n",
        "2.  Fill in the prompt, number of chapters, and writing style in the last cell.\n",
        "3. Run all the cells! After some time, your EPUB file should appear in the filesystem.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HTGF4Bw6Hnuz",
        "outputId": "7ffa8eda-bb92-4dce-90c7-61b744b733c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.16.1-py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.9/266.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting EbookLib\n",
            "  Downloading EbookLib-0.18.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from EbookLib) (4.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from EbookLib) (1.16.0)\n",
            "Building wheels for collected packages: EbookLib\n",
            "  Building wheel for EbookLib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for EbookLib: filename=EbookLib-0.18-py3-none-any.whl size=38778 sha256=cb25ea5aeeb5d447128211e2decced8ce6deb8c55c2589cab2e3c770bd9325f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/38/cc/a3728bb72a315d9d8766fb71d362136372066fc25ad838f8fa\n",
            "Successfully built EbookLib\n",
            "Installing collected packages: EbookLib\n",
            "Successfully installed EbookLib-0.18\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.21.3-py3-none-any.whl (851 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m851.6/851.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.21.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6f3cad8ffcd0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install anthropic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mebooklib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mepub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install EbookLib\n",
        "!pip install anthropic\n",
        "\n",
        "import openai\n",
        "import os\n",
        "from ebooklib import epub\n",
        "import base64\n",
        "import os\n",
        "import requests\n",
        "\n",
        "openai.api_key = \"YOUR OPENAI KEY\" # get it at https://platform.openai.com/\n",
        "stability_api_key = \"YOUR STABILITY KEY\" # get it at https://beta.dreamstudio.ai/\n",
        "anthropic_api_key = \"YOUR ANTHROPIC API KEY\" # optional, if you don't add it, keep it as \"YOUR ANTHROPIC API KEY\"\n",
        "\n",
        "if anthropic_api_key != \"YOUR ANTHROPIC API KEY\":\n",
        "  claude_true = True\n",
        "else:\n",
        "  claude_true = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__nvOnmhPqwy"
      },
      "outputs": [],
      "source": [
        "def generate_cover_prompt(plot):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative assistant that writes a spec for the cover art of a book, based on the book's plot.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Plot: {plot}\\n\\n--\\n\\nDescribe the cover we should create, based on the plot. This should be two sentences long, maximum.\"}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "def create_cover_image(plot):\n",
        "\n",
        "  plot = str(generate_cover_prompt(plot))\n",
        "\n",
        "  engine_id = \"stable-diffusion-xl-beta-v2-2-2\"\n",
        "  api_host = os.getenv('API_HOST', 'https://api.stability.ai')\n",
        "  api_key = stability_api_key\n",
        "\n",
        "  if api_key is None:\n",
        "      raise Exception(\"Missing Stability API key.\")\n",
        "\n",
        "  response = requests.post(\n",
        "      f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n",
        "      headers={\n",
        "          \"Content-Type\": \"application/json\",\n",
        "          \"Accept\": \"application/json\",\n",
        "          \"Authorization\": f\"Bearer {api_key}\"\n",
        "      },\n",
        "      json={\n",
        "          \"text_prompts\": [\n",
        "              {\n",
        "                  \"text\": plot\n",
        "              }\n",
        "          ],\n",
        "          \"cfg_scale\": 7,\n",
        "          \"clip_guidance_preset\": \"FAST_BLUE\",\n",
        "          \"height\": 768,\n",
        "          \"width\": 512,\n",
        "          \"samples\": 1,\n",
        "          \"steps\": 30,\n",
        "      },\n",
        "  )\n",
        "\n",
        "  if response.status_code != 200:\n",
        "      raise Exception(\"Non-200 response: \" + str(response.text))\n",
        "\n",
        "  data = response.json()\n",
        "\n",
        "  for i, image in enumerate(data[\"artifacts\"]):\n",
        "      with open(f\"/content/cover.png\", \"wb\") as f: # replace this if running locally, to where you store the cover file\n",
        "          f.write(base64.b64decode(image[\"base64\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w-tRWAVDf-V"
      },
      "outputs": [],
      "source": [
        "def create_epub(title, author, chapters, cover_image_path='cover.png'):\n",
        "    book = epub.EpubBook()\n",
        "\n",
        "    # Set metadata\n",
        "    book.set_identifier('id123456')\n",
        "    book.set_title(title)\n",
        "    book.set_language('en')\n",
        "    book.add_author(author)\n",
        "\n",
        "    # Add cover image\n",
        "    with open(cover_image_path, 'rb') as cover_file:\n",
        "        cover_image = cover_file.read()\n",
        "    book.set_cover('cover.png', cover_image)\n",
        "\n",
        "    # Create chapters and add them to the book\n",
        "    epub_chapters = []\n",
        "    for i, chapter_dict in enumerate(chapters):\n",
        "        full_chapter_title = list(chapter_dict.keys())[0]\n",
        "        chapter_content = list(chapter_dict.values())[0]\n",
        "        if ' - ' in full_chapter_title:\n",
        "            chapter_title = full_chapter_title.split(' - ')[1]\n",
        "        else:\n",
        "            chapter_title = full_chapter_title\n",
        "\n",
        "        chapter_file_name = f'chapter_{i+1}.xhtml'\n",
        "        epub_chapter = epub.EpubHtml(title=chapter_title, file_name=chapter_file_name, lang='en')\n",
        "\n",
        "        # Add paragraph breaks\n",
        "        formatted_content = ''.join(f'<p>{paragraph.strip()}</p>' for paragraph in chapter_content.split('\\n') if paragraph.strip())\n",
        "\n",
        "        epub_chapter.content = f'<h1>{chapter_title}</h1>{formatted_content}'\n",
        "        book.add_item(epub_chapter)\n",
        "        epub_chapters.append(epub_chapter)\n",
        "\n",
        "\n",
        "    # Define Table of Contents\n",
        "    book.toc = (epub_chapters)\n",
        "\n",
        "    # Add default NCX and Nav files\n",
        "    book.add_item(epub.EpubNcx())\n",
        "    book.add_item(epub.EpubNav())\n",
        "\n",
        "    # Define CSS style\n",
        "    style = '''\n",
        "    @namespace epub \"http://www.idpf.org/2007/ops\";\n",
        "    body {\n",
        "        font-family: Cambria, Liberation Serif, serif;\n",
        "    }\n",
        "    h1 {\n",
        "        text-align: left;\n",
        "        text-transform: uppercase;\n",
        "        font-weight: 200;\n",
        "    }\n",
        "    '''\n",
        "\n",
        "    # Add CSS file\n",
        "    nav_css = epub.EpubItem(uid=\"style_nav\", file_name=\"style/nav.css\", media_type=\"text/css\", content=style)\n",
        "    book.add_item(nav_css)\n",
        "\n",
        "    # Create spine\n",
        "    book.spine = ['nav'] + epub_chapters\n",
        "\n",
        "    # Save the EPUB file\n",
        "    epub.write_epub(f'{title}.epub', book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEClRDpDK7VW"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import random\n",
        "import json\n",
        "import ast\n",
        "from anthropic import Anthropic\n",
        "\n",
        "def print_step_costs(response, model):\n",
        "  input = response['usage']['prompt_tokens']\n",
        "  output = response['usage']['completion_tokens']\n",
        "\n",
        "  if model == \"gpt-4\" or model == \"gpt-4\":\n",
        "    input_per_token = 0.00003\n",
        "    output_per_token = 0.00006\n",
        "  if model == \"gpt-3.5-turbo-16k\":\n",
        "    input_per_token = 0.000003\n",
        "    output_per_token = 0.000004\n",
        "  if model == \"gpt-4-32k\" or model == \"gpt-4-32k\":\n",
        "    input_per_token = 0.00006\n",
        "    output_per_token = 0.00012\n",
        "  if model == \"gpt-3.5-turbo\" or model == \"gpt-3.5-turbo\":\n",
        "    input_per_token = 0.0000015\n",
        "    output_per_token = 0.000002\n",
        "  if model == \"claude-2\":\n",
        "    input_per_token = 0.00001102\n",
        "    output_per_token = 0.00003268\n",
        "\n",
        "  input_cost = int(input) * input_per_token\n",
        "  output_cost = int(output) * output_per_token\n",
        "\n",
        "  total_cost = input_cost + output_cost\n",
        "  print('Step Cost (OpenAI):', total_cost)\n",
        "\n",
        "def print_step_costs_anthropic(prompt, response):\n",
        "  client = Anthropic()\n",
        "  in_tokens = client.count_tokens(prompt)\n",
        "  out_tokens = client.count_tokens(response)\n",
        "\n",
        "  input_cost = 0.00001102 * in_tokens\n",
        "  output_cost = 0.00003268 * out_tokens\n",
        "\n",
        "  total_cost = input_cost + output_cost\n",
        "  print('Step Cost (Anthropic):', total_cost)\n",
        "\n",
        "def generate_plots(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a creative assistant that generates engaging fantasy novel plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Generate 10 fantasy novel plots based on this prompt: {prompt}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "    return response['choices'][0]['message']['content'].split('\\n')\n",
        "\n",
        "def select_most_engaging(plots):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in writing fantastic fantasy novel plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here are a number of possible plots for a new novel: {plots}\\n\\n--\\n\\nNow, write the final plot that we will go with. It can be one of these, a mix of the best elements of multiple, or something completely new and better. The most important thing is the plot should be fantastic, unique, and engaging.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def improve_plot(plot):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in improving and refining story plots.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Improve this plot: {plot}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def get_title(plot):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo-16k\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert writer.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the plot: {plot}\\n\\nWhat is the title of this book? Just respond with the title, do nothing else.\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-3.5-turbo-16k\")\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "def write_first_chapter(plot, first_chapter_title, writing_style, claude=True):\n",
        "    if claude:\n",
        "      url = \"https://api.anthropic.com/v1/complete\"\n",
        "\n",
        "      headers = {\n",
        "          \"anthropic-version\": \"2023-06-01\",\n",
        "          \"content-type\": \"application/json\",\n",
        "          \"x-api-key\": anthropic_api_key,\n",
        "      }\n",
        "\n",
        "      prompt_one = f\"\\n\\nHuman: You are a world-class fantasy writer. I will give you the title of a novel, a high-level plot to follow, and a desired writing style to use. From the title, plot, and writing style, write the first chapter of the novel. Make it incredibly unique, engaging, and well-written. Start it off with a bang, and include dialogue. Include only the chapter text, and no surrounding explanations or text. Do you understand?\\n\\nAssistant: Yes, I understand. Please provide the title, plot, and writing style, and I will write a fantastic opening chapter with dialogue that will hook the reader.\\n\\nHuman: Here is the high-level plot to follow: {plot}\\n\\The title of the novel is: `{first_chapter_title}`.\\n\\nHere is a description of the writing style you should use: `{writing_style}`\\n\\nWrite the first chapter please!\\n\\nAssistant: Okay, I've got a really exciting first chapter for you. It's twenty paragraphs long and very well-written. As you can see, the language I use is very understandable — I avoided using overly complex words and phrases:\\n\\nTitle: {first_chapter_title}\\n\\nChapter #1 Text```\"\n",
        "\n",
        "      data = {\n",
        "      \"model\": \"claude-2\",\n",
        "      \"prompt\": prompt_one,\n",
        "      \"max_tokens_to_sample\": 5000,\n",
        "      }\n",
        "\n",
        "      response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "      initial_first_chapter = response.json()['completion'].strip().split('```')[0].strip()\n",
        "\n",
        "      print_step_costs_anthropic(prompt_one, response.json()['completion'])\n",
        "\n",
        "      prompt_two = f\"\\n\\nHuman: You are a world-class fantasy writer. Your job is to take your student's rough initial draft of the first chapter of their fantasy novel, and rewrite it to be significantly better, with much more detail. Do you understand?\\n\\nAssistant: Yes, I understand. Please provide the plot and the student-written chapter, and I will rewrite the chapter in a far superior way.\\n\\nHuman: Here is the high-level plot you asked your student to follow: {plot}\\n\\nHere is the first chapter they wrote: {initial_first_chapter}\\n\\nNow, rewrite the first chapter of this novel, in a way that is far superior to your student's chapter. It should still follow the exact same plot, but it should be far more detailed, much longer, and more engaging. Here is a description of the writing style you should use: `{writing_style}`\\n\\nAssistant: Okay, I've rewritten the first chapter. I took great care to improve it. While the plot is the same, you can see that my version is noticeably longer, easier to read, and more exciting. Also, the language I used is far more accessible to a broader audience.\\n\\n```\"\n",
        "      data = {\n",
        "      \"model\": \"claude-2\",\n",
        "      \"prompt\": prompt_two,\n",
        "      \"max_tokens_to_sample\": 5000,\n",
        "      }\n",
        "\n",
        "      response_improved = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "      print_step_costs_anthropic(prompt_two, response_improved.json()['completion'])\n",
        "\n",
        "      return response_improved.json()['completion'].strip().split('```')[0].strip()\n",
        "\n",
        "\n",
        "    else:\n",
        "      response = openai.ChatCompletion.create(\n",
        "          model=\"gpt-4\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer.\"},\n",
        "              {\"role\": \"user\", \"content\": f\"Here is the high-level plot to follow: {plot}\\n\\nWrite the first chapter of this novel: `{first_chapter_title}`.\\n\\nMake it incredibly unique, engaging, and well-written.\\n\\nHere is a description of the writing style you should use: `{writing_style}`\\n\\nInclude only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "          ]\n",
        "      )\n",
        "\n",
        "      print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "      improved_response = openai.ChatCompletion.create(\n",
        "          model=\"gpt-4-32k\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer. Your job is to take your student's rough initial draft of the first chapter of their fantasy novel, and rewrite it to be significantly better, with much more detail.\"},\n",
        "              {\"role\": \"user\", \"content\": f\"Here is the high-level plot you asked your student to follow: {plot}\\n\\nHere is the first chapter they wrote: {response['choices'][0]['message']['content']}\\n\\nNow, rewrite the first chapter of this novel, in a way that is far superior to your student's chapter. It should still follow the exact same plot, but it should be far more detailed, much longer, and more engaging. Here is a description of the writing style you should use: `{writing_style}`\"}\n",
        "          ]\n",
        "      )\n",
        "\n",
        "      print_step_costs(response, \"gpt-4-32k\")\n",
        "\n",
        "      return improved_response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "def write_chapter(previous_chapters, plot, chapter_title, claude=True):\n",
        "    if claude:\n",
        "        url = \"https://api.anthropic.com/v1/complete\"\n",
        "\n",
        "        headers = {\n",
        "            \"anthropic-version\": \"2023-06-01\",\n",
        "            \"content-type\": \"application/json\",\n",
        "            \"x-api-key\": anthropic_api_key,\n",
        "        }\n",
        "\n",
        "        prompt = f\"\\n\\nHuman: You are a world-class fantasy writer. I will provide you with the plot of the novel, the previous chapters, and the plan for the next chapter. Your task is to write the next chapter of the novel, following the plot and taking in the previous chapters as context. Do you understand?\\n\\nAssistant: Yes, I understand. You want me to write the next chapter of a novel, using the plot you provide, the previous chapters for context, and a specific plan for the next chapter. I will ensure the chapter is beautifully written and I will not rewrite the chapter name.\\n\\nHuman: That's correct. Here is the plot: {plot}\\n\\nHere are the previous chapters: {previous_chapters}\\n\\nHere is the plan for the next chapter: {chapter_title}\\n\\nWrite it beautifully. Include only the chapter text. There is no need to rewrite the chapter name.\\n\\nAssistant: Here is the next chapter. As you can see, it's around the same length as the previous chapters, and contains witty dialogue:\\n```Chapter\"\n",
        "\n",
        "        data = {\n",
        "            \"model\": \"claude-2\",\n",
        "            \"prompt\": prompt,\n",
        "            \"max_tokens_to_sample\": 5000,\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "        print_step_costs_anthropic(prompt, response.json()['completion'])\n",
        "\n",
        "        return 'Chapter ' + response.json()['completion'].strip().split('```')[0].strip()\n",
        "    else:\n",
        "        try:\n",
        "            i = random.randint(1,2242)\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Plot: {plot}, Previous Chapters: {previous_chapters}\\n\\n--\\n\\nWrite the next chapter of this novel, following the plot and taking in the previous chapters as context. Here is the plan for this chapter: {chapter_title}\\n\\nWrite it beautifully. Include only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "            return response['choices'][0]['message']['content']\n",
        "        except:\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model=\"gpt-4-32k\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer.\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Plot: {plot}, Previous Chapters: {previous_chapters}\\n\\n--\\n\\nWrite the next chapter of this novel, following the plot and taking in the previous chapters as context. Here is the plan for this chapter: {chapter_title}\\n\\nWrite it beautifully. Include only the chapter text. There is no need to rewrite the chapter name.\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            print_step_costs(response, \"gpt-4-32k\")\n",
        "\n",
        "            return response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "def generate_storyline(prompt, num_chapters):\n",
        "    print(\"Generating storyline with chapters and high-level details...\")\n",
        "    json_format = \"\"\"[{\"Chapter CHAPTER_NUMBER_HERE - CHAPTER_TITLE_GOES_HERE\": \"CHAPTER_OVERVIEW_AND_DETAILS_GOES_HERE\"}, ...]\"\"\"\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer. Your job is to write a detailed storyline, complete with chapters, for a fantasy novel. Don't be flowery -- you want to get the message across in as few words as possible. But those words should contain lots of information.\"},\n",
        "            {\"role\": \"user\", \"content\": f'Write a fantastic storyline with {num_chapters} chapters and high-level details based on this plot: {prompt}.\\n\\nDo it in this list of dictionaries format {json_format}'}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(response, \"gpt-4\")\n",
        "\n",
        "    improved_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a world-class fantasy writer. Your job is to take your student's rough initial draft of the storyline of a fantasy novel, and rewrite it to be significantly better.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Here is the draft storyline they wrote: {response['choices'][0]['message']['content']}\\n\\nNow, rewrite the storyline, in a way that is far superior to your student's version. It should have the same number of chapters, but it should be much improved in as many ways as possible. Remember to do it in this list of dictionaries format {json_format}\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print_step_costs(improved_response, \"gpt-4\")\n",
        "\n",
        "    return improved_response['choices'][0]['message']['content']\n",
        "\n",
        "\n",
        "def write_to_file(prompt, content):\n",
        "\n",
        "    # Create a directory for the prompts if it doesn't exist\n",
        "    if not os.path.exists('prompts'):\n",
        "        os.mkdir('prompts')\n",
        "\n",
        "    # Replace invalid characters for filenames\n",
        "    valid_filename = ''.join(c for c in prompt if c.isalnum() or c in (' ', '.', '_')).rstrip()\n",
        "    file_path = f'prompts/{valid_filename}.txt'\n",
        "\n",
        "    with open(file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    print(f'Output for prompt \"{prompt}\" has been written to {file_path}\\n')\n",
        "\n",
        "\n",
        "def write_fantasy_novel(prompt, num_chapters, writing_style, claude_true=False):\n",
        "    plots = generate_plots(prompt)\n",
        "    print('generated plots')\n",
        "\n",
        "    best_plot = select_most_engaging(plots)\n",
        "    print('selected best plot')\n",
        "\n",
        "    improved_plot = improve_plot(best_plot)\n",
        "    print('plot improved')\n",
        "\n",
        "    title = get_title(improved_plot)\n",
        "    print('title generated')\n",
        "\n",
        "    storyline = generate_storyline(improved_plot, num_chapters)\n",
        "    print('storyline generated')\n",
        "    chapter_titles = ast.literal_eval(storyline)\n",
        "\n",
        "\n",
        "    novel = f\"Storyline:\\n{storyline}\\n\\n\"\n",
        "\n",
        "    first_chapter = write_first_chapter(storyline, chapter_titles[0], writing_style.strip(), claude_true)\n",
        "    print('first chapter written')\n",
        "    novel += f\"Chapter 1:\\n{first_chapter}\\n\"\n",
        "    chapters = [first_chapter]\n",
        "\n",
        "    for i in range(num_chapters - 1):\n",
        "        print(f\"Writing chapter {i+2}...\") # + 2 because the first chapter was already added\n",
        "\n",
        "        chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "        try:\n",
        "          if len(str(chapter)) < 100:\n",
        "            print('Length minimum not hit. Trying again.')\n",
        "            chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "        except:\n",
        "          chapter = write_chapter(novel, storyline, chapter_titles[i+1])\n",
        "\n",
        "        novel += f\"Chapter {i+2}:\\n{chapter}\\n\"\n",
        "        chapters.append(chapter)\n",
        "\n",
        "    return novel, title, chapters, chapter_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZeHy7qyACCb"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "prompt = \"A kingdom hidden deep in the forest, where every tree is a portal to another world.\"\n",
        "num_chapters = 10\n",
        "writing_style = \"Clear and easily understandable, similar to a young adult novel. Lots of dialogue.\"\n",
        "novel, title, chapters, chapter_titles = write_fantasy_novel(prompt, num_chapters, writing_style, claude_true)\n",
        "\n",
        "# Replace chapter descriptions with body text in chapter_titles\n",
        "for i, chapter in enumerate(chapters):\n",
        "    chapter_number_and_title = list(chapter_titles[i].keys())[0]\n",
        "    chapter_titles[i] = {chapter_number_and_title: chapter}\n",
        "\n",
        "# Create the cover\n",
        "create_cover_image(str(chapter_titles))\n",
        "\n",
        "# Create the EPUB file\n",
        "create_epub(title, 'AI', chapter_titles, '/content/cover.png')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}